# ETraffic-Analytics ğŸš€
![](static/images/logo.png)
A simple **web traffic analysis project** for **Ethqan Technologies**, built with **Hadoop Streaming** and **Python** (mapper & reducer).  

This project demonstrates how to run a basic **MapReduce job** on a single-node Hadoop cluster, processing ~10,000 records to analyze website traffic.

---

## ğŸ“‚ Repository Structure

ETraffic-Analytics/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input.txt              # Sample input dataset
â”‚   â””â”€â”€ expected_output.txt    # Reference output (optional)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ mapper.py              # Mapper script
â”‚   â”œâ”€â”€ reducer.py             # Reducer script
â”‚   â””â”€â”€ run.sh                 # Helper script to run Hadoop job
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ project_overview.md    # Project explanation
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

---

## âš™ï¸ Prerequisites

- Java 8+
- Hadoop (single-node / pseudo-distributed mode)
- Python 3

Verify Hadoop is installed:

    hadoop version

---

## ğŸš€ Running the Project

1. Start Hadoop services

    start-dfs.sh
    start-yarn.sh

2. Upload input data to HDFS

    hdfs dfs -mkdir -p /user/hadoop/input
    hdfs dfs -put data/input.txt /user/hadoop/input/

3. Run the MapReduce job

    bash src/run.sh

   This uses Hadoop Streaming to run the Python `mapper.py` and `reducer.py`.

4. View the output

    hdfs dfs -cat /user/hadoop/output/part-00000

---

## ğŸ§© Example

Input (data/input.txt):

    192.168.1.1 GET /index.html
    192.168.1.2 GET /contact.html
    192.168.1.1 GET /about.html

Output (aggregated visits per IP):

    192.168.1.1    2
    192.168.1.2    1

---

## ğŸ“œ License
This project is licensed under the MIT License â€” see the LICENSE file for details.

---

## âœ¨ Credits
Developed by **Ethqan Technologies** as a simple demonstration of Big Data processing with Hadoop.
